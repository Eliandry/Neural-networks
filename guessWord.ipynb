{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "guessWord.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAFZSLoUnKjIRHA1gYCAWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eliandry/Neural-networks/blob/main/guessWord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZXa2ffvxXSw"
      },
      "source": [
        "import os\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "from keras.layers import Dense,SimpleRNN,Input,Embedding\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\r\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJRNhhbvy99o"
      },
      "source": [
        "with open('/content/fan', 'r', encoding='utf-8') as f:\r\n",
        "    texts = f.read()\r\n",
        "    texts = texts.replace('\\ufeff', '')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMbN4P6HzJPh",
        "outputId": "7f7eb4be-28f6-4171-b3db-d205f7c459c5"
      },
      "source": [
        "maxWordsCount = 1000\r\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\r\n",
        "                      lower=True, split=' ', char_level=False)\r\n",
        "tokenizer.fit_on_texts([texts])\r\n",
        "\r\n",
        "dist = list(tokenizer.word_counts.items())\r\n",
        "print(dist[:10])\r\n",
        "\r\n",
        "data = tokenizer.texts_to_sequences([texts])\r\n",
        "# res = to_categorical(data[0], num_classes=maxWordsCount)\r\n",
        "# print(res.shape)\r\n",
        "res = np.array( data[0] )\r\n",
        "\r\n",
        "inp_words = 2\r\n",
        "n = res.shape[0] - inp_words\r\n",
        "\r\n",
        "X = np.array([res[i:i + inp_words] for i in range(n)])\r\n",
        "Y = to_categorical(res[inp_words:], num_classes=maxWordsCount)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('мы', 35), ('стояли', 2), ('в', 125), ('местечке', 2), ('жизнь', 4), ('армейского', 1), ('офицера', 1), ('известна', 1), ('утром', 2), ('ученье', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5DsRoZI1Phz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15676d32-16c3-43e7-a302-7a3f4164ebdc"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(maxWordsCount, 256, input_length = inp_words))\r\n",
        "model.add(SimpleRNN(128, activation='tanh'))\r\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\r\n",
        "model.summary()\r\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 2, 256)            256000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              129000    \n",
            "=================================================================\n",
            "Total params: 434,280\n",
            "Trainable params: 434,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5dZd9o62o95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b7202e-093b-4e9a-bd77-32a7ea686358"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\r\n",
        "history = model.fit(X, Y, batch_size=32, epochs=80)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "113/113 [==============================] - 2s 9ms/step - loss: 6.7366 - accuracy: 0.0280\n",
            "Epoch 2/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 5.8406 - accuracy: 0.0515\n",
            "Epoch 3/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 5.5997 - accuracy: 0.0833\n",
            "Epoch 4/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 5.1906 - accuracy: 0.1115\n",
            "Epoch 5/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 4.6076 - accuracy: 0.1689\n",
            "Epoch 6/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 4.0503 - accuracy: 0.2549\n",
            "Epoch 7/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 3.5470 - accuracy: 0.3382\n",
            "Epoch 8/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 3.0103 - accuracy: 0.4095\n",
            "Epoch 9/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 2.6375 - accuracy: 0.4736\n",
            "Epoch 10/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 2.2743 - accuracy: 0.5271\n",
            "Epoch 11/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.9969 - accuracy: 0.5719\n",
            "Epoch 12/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.7924 - accuracy: 0.6125\n",
            "Epoch 13/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.6080 - accuracy: 0.6552\n",
            "Epoch 14/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.3695 - accuracy: 0.7102\n",
            "Epoch 15/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.2488 - accuracy: 0.7294\n",
            "Epoch 16/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.1169 - accuracy: 0.7527\n",
            "Epoch 17/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.0344 - accuracy: 0.7677\n",
            "Epoch 18/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.9199 - accuracy: 0.7856\n",
            "Epoch 19/80\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.8494 - accuracy: 0.7903\n",
            "Epoch 20/80\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.7774 - accuracy: 0.8065\n",
            "Epoch 21/80\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.7477 - accuracy: 0.8064\n",
            "Epoch 22/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.6655 - accuracy: 0.8163\n",
            "Epoch 23/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.6355 - accuracy: 0.8272\n",
            "Epoch 24/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.5903 - accuracy: 0.8289\n",
            "Epoch 25/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.5680 - accuracy: 0.8296\n",
            "Epoch 26/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.5313 - accuracy: 0.8388\n",
            "Epoch 27/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.5251 - accuracy: 0.8267\n",
            "Epoch 28/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.4936 - accuracy: 0.8393\n",
            "Epoch 29/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4892 - accuracy: 0.8293\n",
            "Epoch 30/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4520 - accuracy: 0.8387\n",
            "Epoch 31/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4309 - accuracy: 0.8376\n",
            "Epoch 32/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4366 - accuracy: 0.8414\n",
            "Epoch 33/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4154 - accuracy: 0.8445\n",
            "Epoch 34/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.4055 - accuracy: 0.8529\n",
            "Epoch 35/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3775 - accuracy: 0.8505\n",
            "Epoch 36/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3933 - accuracy: 0.8338\n",
            "Epoch 37/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3679 - accuracy: 0.8517\n",
            "Epoch 38/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3722 - accuracy: 0.8436\n",
            "Epoch 39/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3568 - accuracy: 0.8532\n",
            "Epoch 40/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3577 - accuracy: 0.8427\n",
            "Epoch 41/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3580 - accuracy: 0.8403\n",
            "Epoch 42/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3438 - accuracy: 0.8459\n",
            "Epoch 43/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3782 - accuracy: 0.8304\n",
            "Epoch 44/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3370 - accuracy: 0.8499\n",
            "Epoch 45/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3462 - accuracy: 0.8393\n",
            "Epoch 46/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3387 - accuracy: 0.8499\n",
            "Epoch 47/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3392 - accuracy: 0.8352\n",
            "Epoch 48/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3278 - accuracy: 0.8487\n",
            "Epoch 49/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3335 - accuracy: 0.8442\n",
            "Epoch 50/80\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.3237 - accuracy: 0.8468\n",
            "Epoch 51/80\n",
            "113/113 [==============================] - 2s 15ms/step - loss: 0.3273 - accuracy: 0.8428\n",
            "Epoch 52/80\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.3315 - accuracy: 0.8399\n",
            "Epoch 53/80\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.3243 - accuracy: 0.8393\n",
            "Epoch 54/80\n",
            "113/113 [==============================] - 2s 16ms/step - loss: 0.3087 - accuracy: 0.8497\n",
            "Epoch 55/80\n",
            "113/113 [==============================] - 1s 13ms/step - loss: 0.3238 - accuracy: 0.8409\n",
            "Epoch 56/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3261 - accuracy: 0.8377\n",
            "Epoch 57/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2976 - accuracy: 0.8550\n",
            "Epoch 58/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3305 - accuracy: 0.8295\n",
            "Epoch 59/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3067 - accuracy: 0.8446\n",
            "Epoch 60/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3251 - accuracy: 0.8344\n",
            "Epoch 61/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3063 - accuracy: 0.8388\n",
            "Epoch 62/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8397\n",
            "Epoch 63/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3001 - accuracy: 0.8448\n",
            "Epoch 64/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2955 - accuracy: 0.8502\n",
            "Epoch 65/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2994 - accuracy: 0.8501\n",
            "Epoch 66/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2976 - accuracy: 0.8489\n",
            "Epoch 67/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3086 - accuracy: 0.8334\n",
            "Epoch 68/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2978 - accuracy: 0.8407\n",
            "Epoch 69/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3041 - accuracy: 0.8357\n",
            "Epoch 70/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2897 - accuracy: 0.8442\n",
            "Epoch 71/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3195 - accuracy: 0.8303\n",
            "Epoch 72/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.3014 - accuracy: 0.8433\n",
            "Epoch 73/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2985 - accuracy: 0.8430\n",
            "Epoch 74/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2868 - accuracy: 0.8409\n",
            "Epoch 75/80\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.2903 - accuracy: 0.8417\n",
            "Epoch 76/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2906 - accuracy: 0.8519\n",
            "Epoch 77/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2957 - accuracy: 0.8385\n",
            "Epoch 78/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.3069 - accuracy: 0.8341\n",
            "Epoch 79/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2964 - accuracy: 0.8437\n",
            "Epoch 80/80\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 0.2831 - accuracy: 0.8497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD2D2Fcw236X"
      },
      "source": [
        "def buildPhrase(texts, str_len=5):\r\n",
        "    res = texts\r\n",
        "    data = tokenizer.texts_to_sequences([texts])[0]\r\n",
        "    for i in range(str_len):\r\n",
        "        # x = to_categorical(data[i: i + inp_words], num_classes=maxWordsCount)  # преобразуем в One-Hot-encoding\r\n",
        "        # inp = x.reshape(1, inp_words, maxWordsCount)\r\n",
        "        x = data[i: i + inp_words]\r\n",
        "        inp = np.expand_dims(x, axis=0)\r\n",
        "\r\n",
        "        pred = model.predict(inp)\r\n",
        "        indx = pred.argmax(axis=1)[0]\r\n",
        "        data.append(indx)\r\n",
        "\r\n",
        "        res += \" \" + tokenizer.index_word[indx]  # дописываем строку\r\n",
        "\r\n",
        "    return res"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dLKsySF26AC",
        "outputId": "29721566-4d4b-42ed-c9c2-08156f6a62cc"
      },
      "source": [
        "res = buildPhrase(\"кроме двух\")\r\n",
        "print(res)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "кроме двух или трех коих большею частию\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}