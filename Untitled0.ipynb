{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoIg3ascWgjSVA20sJEEvn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eliandry/Neural-networks/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI4ChTUX7Xbp"
      },
      "source": [
        "import os\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "from keras.layers import Dense,SimpleRNN,Input\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXTqgAGu9e1S"
      },
      "source": [
        "with open('/content/train_data', 'r', encoding='utf-8') as f:\r\n",
        "    text = f.read()\r\n",
        "    text = text.replace('\\ufeff', '')  # убираем первый невидимый символ\r\n",
        "    text = re.sub(r'[^А-я ]', '', text)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-hp59BV-HEE",
        "outputId": "2ee9f054-3fa1-4bb9-a95b-3901cd6ebdb4"
      },
      "source": [
        "num_char=34\r\n",
        "tokenizer = Tokenizer(num_words=num_char, char_level=True)\r\n",
        "tokenizer.fit_on_texts([text])\r\n",
        "#print(tokenizer.word_index)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 1, 'о': 2, 'е': 3, 'т': 4, 'и': 5, 'а': 6, 'н': 7, 'с': 8, 'в': 9, 'р': 10, 'м': 11, 'л': 12, 'ь': 13, 'д': 14, 'п': 15, 'у': 16, 'ы': 17, 'з': 18, 'я': 19, 'б': 20, 'ч': 21, 'к': 22, 'й': 23, 'ж': 24, 'г': 25, 'ш': 26, 'х': 27, 'ю': 28, 'ц': 29, 'щ': 30, 'э': 31, 'ф': 32, 'ъ': 33}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN3nwFILAHkN"
      },
      "source": [
        "inp_chars=6\r\n",
        "data=tokenizer.texts_to_matrix(text)\r\n",
        "n=data.shape[0]-inp_chars\r\n",
        "#print(n)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QJmeF1fBkr-"
      },
      "source": [
        "Обуч. выборка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7JSW4PiBA2X",
        "outputId": "5b6875f5-33e2-4d4b-edfe-7411885d46c3"
      },
      "source": [
        "x=np.array([data[i:i + inp_chars, :] for i in range(n)])\r\n",
        "y=data[inp_chars:]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MuBIneiBuCm",
        "outputId": "dd32bf3f-29a9-40ac-9687-702cbfff6c07"
      },
      "source": [
        "model=Sequential()\r\n",
        "model.add(Input((inp_chars,num_char)))\r\n",
        "model.add(SimpleRNN(128,activation='tanh'))\r\n",
        "model.add(Dense(num_char,activation='softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               20864     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 34)                4386      \n",
            "=================================================================\n",
            "Total params: 25,250\n",
            "Trainable params: 25,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbP2OYlJFJ-R"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kI-tcP6FORR"
      },
      "source": [
        "history=model.fit(x,y,batch_size=32,epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpUPXjZ8Fult"
      },
      "source": [
        "def buildPhrase(inp_str, str_len=20):\r\n",
        "    for i in range(str_len):\r\n",
        "        x = []\r\n",
        "        for j in range(i, i + inp_chars):\r\n",
        "            x.append(tokenizer.texts_to_matrix(inp_str[j]))  # преобразуем символы в One-Hot-encoding\r\n",
        "\r\n",
        "        x = np.array(x)\r\n",
        "        inp = x.reshape(1, inp_chars, num_char)\r\n",
        "\r\n",
        "        pred = model.predict(inp)  # предсказываем OHE четвертого символа\r\n",
        "        d = tokenizer.index_word[pred.argmax(axis=1)[0]]  # получаем ответ в символьном представлении\r\n",
        "\r\n",
        "        inp_str += d  # дописываем строку\r\n",
        "    return inp_str"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2T0kdoZGWvp",
        "outputId": "1ca4ec03-106b-4054-ff32-1fb12e8efa02"
      },
      "source": [
        "res = buildPhrase(\"утренн\")\r\n",
        "\r\n",
        "print(res)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "утренние мысли в понедельн\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}